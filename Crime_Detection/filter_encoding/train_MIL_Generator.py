import sys
import os

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utilities.utils import *
from tqdm import tqdm
from utilities.eval_utils import eval
import argparse
from training_pipeline_stage1.MIL_Generator import Simple_Regressor
from torch.utils.data.dataloader import DataLoader
from training_pipeline_stage1.SHT_MIL_dataset import (
    SH_Train_Origin_Dataset,
    shanghaitech_test,
)
import torch.nn.functional as F
import h5py

feature_type = {
    "I3D_RGB": [16, 1024],
    "C3D_RGB": [16, 4096],
}


def topk_rank_loss(args, y_pred):
    topk_pred = torch.mean(
        torch.topk(
            y_pred.view([args.batch_size * 2, args.part_num * args.part_len]),
            args.topk,
            dim=-1,
        )[0],
        dim=-1,
        keepdim=False,
    )

    nor_max = topk_pred[: args.batch_size]
    abn_max = topk_pred[args.batch_size :]

    err = 0
    for i in range(args.batch_size):
        err += torch.sum(F.relu(1 - abn_max + nor_max[i]))
    err = err / (args.batch_size) ** 2

    abn_pred = y_pred[args.batch_size :]
    spar_l1 = torch.mean(abn_pred)
    smooth_l2 = torch.mean((abn_pred[:, :-1] - abn_pred[:, 1:]) ** 2)

    loss = err + args.lambda_1 * spar_l1 + args.lambda_2 * smooth_l2

    return loss, err, spar_l1, smooth_l2, smooth_l2


def train(args):

    def worker_init(worked_id):
        np.random.seed(args.seed + worked_id)
        random.seed(args.seed + worked_id)

    dataset = SH_Train_Origin_Dataset(
        args.part_num,
        args.part_len,
        args.feature_rgb_path,
        args.training_txt,
        args.sample,
        None,  # args.Pseudo_Labels_dir+'pseudo_labels.npy'
        args.norm,
    )
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        num_workers=4,
        worker_init_fn=worker_init,
        drop_last=True,
    )
    model = Simple_Regressor(args.size, args.dropout_rate).cuda().train()
    optimizer = torch.optim.Adagrad(model.parameters(), lr=args.lr, weight_decay=0.001)
    test_feats, test_labels, test_annos = shanghaitech_test(
        args.testing_txt, args.test_mask_dir, args.feature_rgb_path, args.norm
    )
    best_AUC = 0
    best_iter = 0
    count = 0
    for epoch in range(args.epochs):
        for norm_feats, norm_labs, abnorm_feats, abnorm_labs in dataloader:
            feats = (
                torch.cat([norm_feats, abnorm_feats], dim=0)
                .cuda()
                .float()
                .view([args.batch_size * 2, args.part_num * args.part_len, args.size])
            )
            labs = (
                torch.cat([norm_labs, abnorm_labs], dim=0)
                .cuda()
                .float()
                .view([args.batch_size * 2, args.part_num * args.part_len, 1])
            )
            outputs = model(feats)
            outputs = outputs.view(
                [args.batch_size * 2, args.part_num * args.part_len, -1]
            )
            outputs_mean = torch.mean(outputs, dim=-1, keepdim=True)

            loss, err, l1, _, l3 = topk_rank_loss(args, outputs_mean)

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 10)
            optimizer.step()

            # if count % 10 == 0:
            print(
                "[{}/{}]: loss {:.4f}, err {:.4f}, l1 {:.4f}ï¼Œ l2 {:.4f} kl {:.4f}".format(
                    count, epoch, loss, err, l1, l3, kl
                )
            )
            count += 1
        dataloader.dataset.shuffle_keys()
        if epoch % 10 == 0:
            total_scores = []
            total_labels = []

            with torch.no_grad():
                model = model.eval()
                for test_feat, label, test_anno in zip(
                    test_feats, test_labels, test_annos
                ):
                    test_feat = np.array(test_feat).reshape([-1, args.size])
                    temp_score = []
                    for i in range(test_feat.shape[0]):
                        feat = test_feat[i]
                        feat = (
                            torch.from_numpy(np.array(feat))
                            .float()
                            .cuda()
                            .view([-1, args.size])
                        )
                        logits = model(feat)
                        score = torch.mean(logits).item()
                        temp_score.extend([score] * args.segment_len)

                    total_labels.extend(test_anno[: len(temp_score)].tolist())
                    total_scores.extend(temp_score)
            auc = eval(total_scores, total_labels, None)
            if auc > best_AUC:
                best_iter = epoch
                best_AUC = auc

            if auc > 0.90:
                torch.save(
                    model.state_dict(),
                    args.model_path_pre
                    + "{}_norm_{}_part_num_{}_part_len_{}_epoch_{}_AUC_{}.pth".format(
                        args.type, args.norm, args.part_num, args.part_len, epoch, auc
                    ),
                )
            print("best_AUC {} at epoch {}".format(best_AUC, best_iter))
            print("===================")
            model = model.train()


def parser_arg():
    parser = argparse.ArgumentParser()
    parser.add_argument("--type", type=str, default="I3D_RGB")

    parser.add_argument("--size", type=int, default=1024)
    parser.add_argument("--segment_len", type=int, default=16)
    parser.add_argument("--batch_size", type=int, default=40)

    parser.add_argument("--topk", type=int, default=7)
    parser.add_argument("--part_num", type=int, default=32)
    parser.add_argument("--part_len", type=int, default=7)
    parser.add_argument("--epochs", type=int, default=3001)
    parser.add_argument("--gpu", type=str, default="0")

    parser.add_argument("--lr", type=float, default=0.01)
    parser.add_argument("--weight_decay", type=float, default=0.001)

    parser.add_argument("--dropout_rate", type=float, default=0.6)
    parser.add_argument("--seed", type=int, default=0)
    parser.add_argument(
        "--sample", type=str, default="uniform", help="[random/uniform]"
    )

    parser.add_argument("--norm", type=int, default=0)
    parser.add_argument("--clip", type=float, default=4.0)

    parser.add_argument("--lambda_1", type=float, default=0.01)
    parser.add_argument("--lambda_2", type=float, default=0)

    parser.add_argument("--machine", type=str, default="data0")

    parser.add_argument("--feature_rgb_path", type=str, default="/jiachang/SHT_I3D.h5")
    parser.add_argument(
        "--model_path_pre",
        type=str,
        default="/jiachang/Weakly_Supervised_VAD/models/shanghaitech_single",
    )
    parser.add_argument(
        "--training_txt",
        type=str,
        default="/jiachang/Weakly_Supervised_VAD/Datasets/SH_Train_new.txt",
    )
    parser.add_argument(
        "--testing_txt",
        type=str,
        default="/jiachang/Weakly_Supervised_VAD/Datasets/SH_Test_NEW.txt",
    )
    parser.add_argument(
        "--test_mask_dir",
        type=str,
        default="/jiachang/Weakly_Supervised_VAD/Datasets/test_frame_mask/",
    )
    parser.add_argument(
        "--model_path",
        type=str,
        default="/jiachang/Weakly_Supervised_VAD/Datasets/MIL.pth",
    )
    parser.add_argument(
        "--Pseudo_Labels_dir",
        type=str,
        default="/jiachang/Pseudo_Labels_MultiViews/SHT_PLs_I3D_iter_1",
    )

    parser.add_argument("--generate_PL", action="store_true", dest="PL")
    parser.set_defaults(PL=False)

    parser.add_argument("--smooth_len", type=int, default=5)

    args = parser.parse_args()
    args.machine = "/" + args.machine
    args.feature_rgb_path = args.machine + args.feature_rgb_path
    args.model_path_pre = args.machine + args.model_path_pre
    args.training_txt = args.machine + args.training_txt
    args.testing_txt = args.machine + args.testing_txt
    args.test_mask_dir = args.machine + args.test_mask_dir
    args.model_path = args.machine + args.model_path
    args.Pseudo_Labels_dir = args.machine + args.Pseudo_Labels_dir

    return args


def Augment_Pseudo_Label_Generate(args):
    model = Simple_Regressor(feature_type[args.type][1]).cuda().eval()
    test_keys = []
    for line in open(args.testing_txt).readlines():
        test_keys.append(line.strip().split(",")[0].split(".")[0] + ".npy")

    model.load_state_dict(torch.load(args.model_path))
    scores_dict = {}
    test_scores_dict = {}

    with h5py.File(args.feature_rgb_path, "r") as h5:
        keys = list(h5.keys())
        # import pdb
        # pdb.set_trace()
        with torch.no_grad():
            for key in keys:
                feat = h5[key][:]
                feat = np.array(feat)
                if args.norm == 2:
                    feat = feat / np.linalg.norm(feat, axis=-1, keepdims=True)
                feat = torch.from_numpy(feat).cuda().float()
                if feat.shape[0] > 1000:
                    scores = []
                    length = feat.shape[0] // 1000 + 1
                    for i in range(length):
                        if i == length - 1:
                            f = feat[i * 1000 :]
                        else:
                            f = feat[i * 1000 : (i + 1) * 1000]
                        scores.append(model(f).detach().cpu().numpy())
                    scores = np.vstack(scores)
                else:
                    scores = model(feat).detach().cpu().numpy()
                scores = scores.squeeze()
                if key in test_keys:
                    test_scores_dict[key] = scores
                else:
                    scores_dict[key] = scores
    np.save(args.Pseudo_Labels_dir + "/train_results.npy", scores_dict)
    np.save(args.Pseudo_Labels_dir + "/test_results.npy", test_scores_dict)

    Augment_Pseudo_Label_Refilement(args)


def smooth(y, box_size):
    assert box_size % 2 == 1, "The bosx size should be ood"
    box = np.ones(box_size) / box_size
    y = np.array([y[0]] * (box_size // 2) + y.tolist() + [y[-1]] * (box_size // 2))
    y_smooth = np.convolve(y, box, mode="valid")
    return y_smooth


def Augment_Pseudo_Label_Refilement(args):
    lines = open(args.training_txt, "r").readlines()
    train_score_dict = np.load(
        args.Pseudo_Labels_dir + "/train_results.npy", allow_pickle=True
    ).tolist()
    output_labels_dict = {}
    for line in tqdm(lines):
        line_split = line.strip().split(",")
        label = int(line_split[-1])
        key = line_split[0] + ".npy"
        score = train_score_dict[key]
        if label == 1:
            score = smooth(score, args.smooth_len)
            score = smooth(score, args.smooth_len)
            if score.shape[0] >= 2:
                score = score - score.min()
                score = score / score.max()
            output_labels_dict[key] = score
        else:
            score = smooth(score, args.smooth_len)
            score = smooth(score, args.smooth_len)
            output_labels_dict[key] = score
    np.save(args.Pseudo_Labels_dir + "/pseudo_labels.npy", output_labels_dict)
    print("finished!")


if __name__ == "__main__":
    args = parser_arg()
    os.environ["CUDA_VISIBLE_DEVICES"] = args.gpu

    set_seeds(args.seed)
    if not args.PL:
        train(args)
    else:
        Augment_Pseudo_Label_Generate(args)
